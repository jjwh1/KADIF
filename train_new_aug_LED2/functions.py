from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms.functional as TF
import torchvision.transforms as transforms
import numpy as np
import ast
from glob import glob
import os
from pathlib import Path
import argparse

from PIL import ImageFile, Image
ImageFile.LOAD_TRUNCATED_IMAGES = True
import random

from torch.utils.data._utils.collate import default_collate
from degra_for_aug import build_transform


def collate_with_meta(batch):
    """
    batch: list of samples; each sample is either
      (img, label) or (img, label, meta)
    ë°˜í™˜:
      imgs:  Tensor [B, C, H, W]
      labels: Tensor [B, H, W]
      metas:  list[dict] ê¸¸ì´ B (ë©”íƒ€ ì—†ë˜ ê²½ìš° ë¹ˆ dict ì œê³µ)
    """
    imgs, labels, metas = [], [], []
    for sample in batch:
        if len(sample) == 3:
            img, lab, meta = sample
        else:
            img, lab = sample
            meta = {}  # ê²€ì¦ì…‹ ë“± ë©”íƒ€ ì—†ëŠ” ê²½ìš°
        imgs.append(img)
        labels.append(lab)
        metas.append(meta)
    return torch.stack(imgs, dim=0), torch.stack(labels, dim=0), metas


def arg_as_list(s):
    v = ast.literal_eval(s)
    if type(v) is not list:
        raise argparse.ArgumentTypeError("Argument \"%s\" is not a list" % (s))
    return v

def display_dataset_info(datadir, dataset):      
    print(f'Dataset path: {datadir}')    
    if dataset is not None:
        print(f"Found {len(dataset)} images.")    

def load_state_dict(model, state_dict):
    """
    model.module vs model key mismatch ë¬¸ì œë¥¼ ìžë™ìœ¼ë¡œ í•´ê²°
    """
    from collections import OrderedDict

    new_state_dict = OrderedDict()

    is_ddp = isinstance(model, torch.nn.parallel.DistributedDataParallel)

    for k, v in state_dict.items():
        if is_ddp:
            if not k.startswith('module.'):
                k = 'module.' + k
        else:
            if k.startswith('module.'):
                k = k[len('module.'):]
        new_state_dict[k] = v

    model.load_state_dict(new_state_dict, strict=False)
    model_keys = set(model.state_dict().keys())
    loaded_keys = set(new_state_dict.keys()) & model_keys

    total = len(model_keys)
    loaded = len(loaded_keys)
    percent = 100.0 * loaded / total if total > 0 else 0.0

    print(f"[Info] Loaded {loaded}/{total} state_dict entries ({percent:.2f}%) from checkpoint.")

class SegmentationTransform:
    def __init__(
        self,
        crop_size=(1024, 1024),
        scale_range=(0.5, 1.5),
        is_train=True,
        mean=(0.485, 0.456, 0.406),
        std=(0.229, 0.224, 0.225),
        val_resize_size=(1080, 1920),
        normal_aug_prob=0.5,  # normal ì´ë¯¸ì§€ì— degradation ì ìš©í•  í™•ë¥ 
        normal_aug_chains=None,  # normalì—ì„œ ì‚¬ìš©í•  ì¡°í•©(ì—†ìœ¼ë©´ ê¸°ë³¸ 5ì¢…)
        severity_range=(1, 5),  # ê° degradation ê°•ë„ ëžœë¤ ë²”ìœ„
    ):
        self.crop_size = crop_size  # (H, W)
        self.scale_range = scale_range
        self.is_train = is_train
        self.val_resize_size = val_resize_size

        self.mean = mean
        self.std = std

        self.bilinear = transforms.InterpolationMode.BILINEAR
        self.nearest = transforms.InterpolationMode.NEAREST

        self.normal_aug_prob = float(normal_aug_prob)
        self.severity_range = (int(severity_range[0]), int(severity_range[1]))

        default_chains = [
            ("rain", "raindrop", "low_light"),
            ("rain", "raindrop"),
            ("rain", "raindrop", "haze"),
            ("low_light",),
            ("haze",),
        ]
        self.normal_aug_chains = list(normal_aug_chains) if normal_aug_chains else default_chains

    # ---- ë‚´ë¶€ ìœ í‹¸: ê¸°í•˜ ì¦ê°• ----
    def _random_scale(self, image, label):
        s = random.uniform(self.scale_range[0], self.scale_range[1])
        w, h = image.size
        nw, nh = max(1, int(w * s)), max(1, int(h * s))
        image = TF.resize(image, (nh, nw), interpolation=self.bilinear)
        label = TF.resize(label, (nh, nw), interpolation=self.nearest)
        return image, label

    def _pad_and_random_crop(self, image, label):
        H, W = self.crop_size
        _, h, w = 0, image.size[1], image.size[0]
        pad_h, pad_w = max(H - h, 0), max(W - w, 0)
        if pad_h > 0 or pad_w > 0:
            # left, top, right, bottom
            image = TF.pad(image, (0, 0, pad_w, pad_h), fill=0)
            label = TF.pad(label, (0, 0, pad_w, pad_h), fill=255)
        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=self.crop_size)
        image = TF.crop(image, i, j, h, w)
        label = TF.crop(label, i, j, h, w)
        return image, label

    def _random_hflip(self, image, label, p=0.5):
        if random.random() < p:
            image = TF.hflip(image)
            label = TF.hflip(label)
        return image, label

    def _resize_to(self, image, label, size_hw):
        H, W = int(size_hw[0]), int(size_hw[1])
        image = TF.resize(image, (H, W), interpolation=self.bilinear)
        label = TF.resize(label, (H, W), interpolation=self.nearest)
        return image, label

    # --- ë‹¨ì¼ ì¦ê°• ì ìš©(ê°•ë„ ëžœë¤) ---
    def _apply_single_aug(self, image, aug_name):
        sev = random.randint(self.severity_range[0], self.severity_range[1])
        t = build_transform(aug_name, sev)
        return t(image), (aug_name, sev)

    # --- ì²´ì¸ ì¦ê°• ì ìš© (ì—¬ëŸ¬ ê°œ ìˆœì°¨ ì ìš©) ---
    def _apply_aug_chain(self, image, chain_names):
        out = image
        applied = []
        for name in chain_names:
            out, item = self._apply_single_aug(out, name)
            applied.append(item)  # (aug_name, sev)
        return out, applied

    def __call__(self, image, label, tag="normal"):
        # === íƒœê·¸ ê¸°ë°˜ degradation ì¦ê°• ===
        tag = (tag or "normal").lower()

        if not self.is_train:
            # VALID: ToTensor + Normalize ë§Œ
            if self.val_resize_size is not None:
                image, label = self._resize_to(image, label, self.val_resize_size)

            img_t = TF.to_tensor(image)
            img_t = TF.normalize(img_t, self.mean, self.std)
            lab_t = torch.from_numpy(np.array(label, dtype=np.uint8)).long()
            meta = {"tag": tag, "applied": []}  # ê²€ì¦ì—ì„œë„ meta ë°˜í™˜(ë¹ˆ ë¦¬ìŠ¤íŠ¸)
            return img_t, lab_t, meta  # í•­ìƒ 3ê°œ ë°˜í™˜

        # TRAIN: ê¸°í•˜ ì¦ê°•
        image, label = self._random_scale(image, label)
        image, label = self._pad_and_random_crop(image, label)
        image, label = self._random_hflip(image, label, p=0.5)

        applied = []  # â† ì´ë²ˆ ìƒ˜í”Œì— ì‹¤ì œ ì ìš©ëœ ì¦ê°•ë“¤
        # if tag == "low_light":
        #     image, applied = self._apply_aug_chain(image, ["overbright"])
        if tag == "normal":
            if random.random() < self.normal_aug_prob:
                chain = random.choice(self.normal_aug_chains)
                image, applied = self._apply_aug_chain(image, chain)

        # ToTensor + Normalize
        img_t = TF.to_tensor(image);
        img_t = TF.normalize(img_t, self.mean, self.std)
        lab_t = torch.from_numpy(np.array(label, dtype=np.uint8)).long()
        meta = {"tag": tag, "applied": applied}  # e.g. {"applied":[("rain",3),("raindrop",2)], ...}
        return img_t, lab_t, meta


# =========================
# í†µí•© Dataset (train/val ê³µìš©)
# - subset: 'train' | 'val'
# - ë¼ë²¨ ê²½ë¡œ: image â†’ labelmap ì¹˜í™˜, íŒŒì¼ëª… ë™ì¼(.png ê°€ì •)
# - íƒœê·¸: ê²½ë¡œì—ì„œ í´ë”ëª… íƒìƒ‰ (low_light / overbright / degradation / normal)
# =========================
class SegmentationDataset(Dataset):
    TAG_ALIASES = {
        "lowlight": "low_light",
        "low_light": "low_light",
        "overlight": "overbright",
        "low_light_byLED": "low_light",
        "overbright": "overbright",
        "degradation": "degradation",
        "normal": "normal",
    }
    IMG_EXTS = {".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff"}

    def __init__(
        self,
        root_dir,
        crop_size=(1024,1024),
        subset="train",                 # 'train' or 'val'
        scale_range=(0.5, 1.5),
        val_resize_size=(1080, 1920),
        normal_aug_prob=0.5,
        severity_range=(1, 5),
    ):
        self.root_dir = os.path.abspath(root_dir)
        self.subset = subset

        # ì´ë¯¸ì§€/ë¼ë²¨ ê²½ë¡œ ìˆ˜ì§‘
        img_pattern = os.path.join(self.root_dir, subset, "*", "image", "**", "*.*")
        all_imgs = sorted(glob(img_pattern, recursive=True))

        image_paths, label_paths, tags = [], [], []
        for p in all_imgs:
            suffix = Path(p).suffix.lower()
            if suffix not in self.IMG_EXTS:
                continue

            # --- train ì„¸íŠ¸ì¼ ë•Œë§Œ low_light í´ë” ì œì™¸ ---
            if self.subset == "train" and "/low_light/" in p.replace("\\", "/"):
                continue

            lp = self._get_label_path(p)  # same tag, labelmapë¡œ ì¹˜í™˜
            if not os.path.exists(lp):
                # í•„ìš”í•˜ë©´ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  continue
                # print(f"[WARN] label not found for {p}")
                continue
            image_paths.append(p)
            label_paths.append(lp)
            tags.append(self._get_tag(p))

        self.image_paths = image_paths
        self.label_paths = label_paths
        self.tags = tags

        # Transform: subsetì— ë”°ë¼ train/val ì „í™˜
        self.transform = SegmentationTransform(
            crop_size=crop_size,
            scale_range=scale_range,
            is_train=(subset == "train"),
            val_resize_size=val_resize_size,
            normal_aug_prob=normal_aug_prob,  # â† í•„ìš” ì‹œ ì¡°ì •
            severity_range=severity_range,  # â† í•„ìš” ì‹œ ì¡°ì •
            normal_aug_chains=[
                ("rain", "raindrop", "low_light"),
                ("rain", "raindrop"),
                ("rain", "raindrop", "haze"),
                ("low_light",),
                ("haze",),
            ]
        )

    # --- image â†’ labelmap ì¹˜í™˜ (ê°™ì€ subset/tag í•˜ìœ„ë¡œ)
    def _get_label_path(self, image_path: str) -> str:
        """
        .../<subset>/<tag>/image/aaa/bbb/CCC.ext
        â†’   .../<subset>/<tag>/labelmap/aaa/bbb/CCC.png
        """
        p = Path(image_path)
        parts = list(p.parts)
        # subset ì¸ë±ìŠ¤ ì°¾ê¸°
        sub_idx = parts.index(self.subset)
        tag = parts[sub_idx + 1]  # low_light, overbright, ...
        # image ë‹¤ìŒì˜ ìƒëŒ€ê²½ë¡œ (íŒŒì¼ëª… í¬í•¨)
        assert parts[sub_idx + 2].lower() == "image"
        rel_inside = Path(*parts[(sub_idx + 3):])  # aaa/bbb/CCC.ext
        # ë¼ë²¨ ê²½ë¡œ ì¡°ë¦½ (í™•ìž¥ìžëŠ” .pngë¡œ í†µì¼)
        lbl = Path(self.root_dir, self.subset, tag, "labelmap", rel_inside).with_suffix(".png")
        return str(lbl)

    # --- ê²½ë¡œì—ì„œ íƒœê·¸ ì¶”ì¶œ
    def _get_tag(self, image_path: str) -> str:
        parts = [s.lower() for s in Path(image_path).parts]
        sub_idx = parts.index(self.subset)
        raw = parts[sub_idx + 1]
        return self.TAG_ALIASES.get(raw, "normal")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        lab = Image.open(self.label_paths[idx]).convert("L")
        tag = self.tags[idx]
        img_t, lab_t, meta = self.transform(img, lab, tag=tag)
        return img_t, lab_t, meta



class CrossEntropy(nn.Module):
    def __init__(self, ignore_label= 255, weight= None, aux_weights = [1, 0.4]):
        super().__init__()
        self.aux_weights = aux_weights
        self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_label)

    def _forward(self, preds, labels):
        # preds in shape [B, C, H, W] and labels in shape [B, H, W]
        return self.criterion(preds, labels)

    def forward(self, preds, labels):
        if isinstance(preds, tuple):
            return sum([w * self._forward(pred, labels) for (pred, w) in zip(preds, self.aux_weights)])
        return self._forward(preds, labels)    
    
    
class OhemCrossEntropy(nn.Module):
    def __init__(self, ignore_label= 255, weight = None, thresh = 0.6, aux_weights= [1, 0.4]):
        super().__init__()
        self.ignore_label = ignore_label
        self.aux_weights = aux_weights
        self.thresh = -torch.log(torch.tensor(thresh, dtype=torch.float))
        self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_label, reduction='none')

    def _forward(self, preds, labels):
        # preds in shape [B, C, H, W] and labels in shape [B, H, W]
        n_min = labels[labels != self.ignore_label].numel() // 16
        loss = self.criterion(preds, labels).view(-1)
        loss_hard = loss[loss > self.thresh]

        if loss_hard.numel() < n_min:
            loss_hard, _ = loss.topk(n_min)

        return torch.mean(loss_hard)

    def forward(self, preds, labels):
        if isinstance(preds, tuple):
            return sum([w * self._forward(pred, labels) for (pred, w) in zip(preds, self.aux_weights)])
        return self._forward(preds, labels)        

import torch.nn as nn
import torch.nn.functional as F

# ðŸ”¹ ìƒˆë¡œ ì¶”ê°€
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=None, ignore_index=255, reduction='mean', aux_weights=[1.0, 0.4]):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.ignore_index = ignore_index
        self.reduction = reduction
        self.aux_weights = aux_weights

    def _forward_single(self, logits, targets):
        ce_loss = F.cross_entropy(
            logits, targets,
            weight=self.alpha,
            ignore_index=self.ignore_index,
            reduction="none"
        )
        logpt = -ce_loss
        pt = torch.exp(logpt)
        focal_term = (1 - pt) ** self.gamma
        loss = focal_term * ce_loss
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss

    def forward(self, logits, targets):
        if isinstance(logits, tuple):  # main_out, aux_out ê°™ì´ ë“¤ì–´ì˜¤ëŠ” ê²½ìš°
            return sum(w * self._forward_single(l, targets) for l, w in zip(logits, self.aux_weights))
        else:
            return self._forward_single(logits, targets)


# focal lossì—ì„œ í•„ìš”í•œ ì—°ì‚°

import torch
import numpy as np
from tqdm import tqdm


def compute_class_weights(dataloader, num_classes, ignore_index=255, method="inverse"):
    """
    dataloader: í•™ìŠµìš© DataLoader (train_loader)
    num_classes: í´ëž˜ìŠ¤ ê°œìˆ˜ (ì˜ˆ: 19)
    ignore_index: ë¬´ì‹œí•  ë¼ë²¨ (ë³´í†µ 255)
    method: "inverse" | "effective_num"

    ë°˜í™˜: torch.Tensor [num_classes]
    """
    counts = np.zeros(num_classes, dtype=np.int64)

    for imgs, labels, _ in tqdm(dataloader, desc="Counting class frequencies"):
        labels = labels.numpy()
        for c in range(num_classes):
            counts[c] += np.sum(labels == c)

    # ----- ë°©ë²• 1: ë‹¨ìˆœ ì—­ë¹„ìœ¨ (Inverse Frequency) -----
    if method == "inverse":
        weights = 1.0 / (counts + 1e-6)  # ë¹ˆë„ê°€ ì ì„ìˆ˜ë¡ í° ê°€ì¤‘ì¹˜
        weights = weights / weights.sum() * num_classes  # ì •ê·œí™”

    # ----- ë°©ë²• 2: Effective Number of Samples (Cui et al., CVPR 2019) -----
    elif method == "effective_num":
        beta = 0.9999
        effective_num = 1.0 - np.power(beta, counts)
        weights = (1.0 - beta) / (effective_num + 1e-6)
        weights = weights / weights.sum() * num_classes

    return torch.tensor(weights, dtype=torch.float32)

import torch
import os

def compute_or_load_class_weights(dataloader, num_classes, cache_path=None,
                                  ignore_index=255, method="effective_num"):
    # ìºì‹œ íŒŒì¼ì´ ìžˆìœ¼ë©´ ë°”ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(cache_path):
        print(f"[Info] Loading precomputed class weights from {cache_path}")
        return torch.load(cache_path)

    # ì—†ìœ¼ë©´ ìƒˆë¡œ ê³„ì‚°
    print("[Info] Computing class weights...")
    weights = compute_class_weights(dataloader, num_classes,
                                    ignore_index=ignore_index, method=method)
    torch.save(weights, cache_path)
    print(f"[Info] Saved class weights to {cache_path}")
    return weights


from torch.optim.lr_scheduler import _LRScheduler

class WarmupCosineAnnealingLR(_LRScheduler):
    def __init__(self, optimizer, total_epochs, warmup_epochs=10, eta_min=0, last_epoch=-1):
        self.total_epochs = total_epochs
        self.warmup_epochs = warmup_epochs
        self.eta_min = eta_min
        super(WarmupCosineAnnealingLR, self).__init__(optimizer, last_epoch)

    def get_lr(self):
        if self.last_epoch < self.warmup_epochs:
            # linear warmup: from 0 to base_lr
            return [
                base_lr * float(self.last_epoch + 1) / self.warmup_epochs
                for base_lr in self.base_lrs
            ]
        else:
            # cosine annealing
            progress = (self.last_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            return [
                self.eta_min + (base_lr - self.eta_min) * 0.5 * (1 + np.cos(np.pi * progress))
                for base_lr in self.base_lrs
            ]    
    


class PolyLR(_LRScheduler):
    def __init__(self, optimizer, total_epochs=500, decay_epoch=1, power=0.9, last_epoch=-1) -> None:
        self.decay_epoch = decay_epoch
        self.total_epochs = total_epochs
        self.power = power
        super().__init__(optimizer, last_epoch=last_epoch)

    def get_lr(self):
        if self.last_epoch % self.decay_epoch != 0 or self.last_epoch > self.total_epochs:
            return self.base_lrs
        else:
            factor = (1 - self.last_epoch / float(self.total_epochs)) ** self.power
            return [factor*lr for lr in self.base_lrs]

class EpochWarmupLR(_LRScheduler):
    def __init__(self, optimizer, warmup_epochs=5, warmup_ratio=5e-4, warmup='linear',total_epochs=500, last_epoch=-1):
        self.warmup_epochs = warmup_epochs
        self.warmup_ratio = warmup_ratio
        self.warmup = warmup
        self.total_epochs = total_epochs
        super().__init__(optimizer, last_epoch)

    def get_lr(self):
        ratio = self.get_lr_ratio()
        return [max(ratio * lr, 1e-7) for lr in self.base_lrs]

    def get_lr_ratio(self):
        if self.last_epoch < self.warmup_epochs:
            return self.get_warmup_ratio()
        return self.get_main_ratio()

    def get_warmup_ratio(self):
        alpha = self.last_epoch / self.warmup_epochs
        if self.warmup == 'linear':
            return self.warmup_ratio + (1. - self.warmup_ratio) * alpha
        else:
            return self.warmup_ratio ** (1. - alpha)

    def get_main_ratio(self):
        raise NotImplementedError
        
        
class WarmupPolyEpochLR(EpochWarmupLR):
    def __init__(self, optimizer, power=0.9, total_epochs=500, warmup_epochs=5, warmup_ratio=5e-4, warmup='linear', last_epoch=-1):
        self.power = power
        super().__init__(optimizer, warmup_epochs, warmup_ratio, warmup, total_epochs, last_epoch)

    def get_main_ratio(self):
        real_epoch = self.last_epoch - self.warmup_epochs
        real_total = self.total_epochs - self.warmup_epochs
        alpha = min(real_epoch / real_total, 1.0)
        return (1 - alpha) ** self.power